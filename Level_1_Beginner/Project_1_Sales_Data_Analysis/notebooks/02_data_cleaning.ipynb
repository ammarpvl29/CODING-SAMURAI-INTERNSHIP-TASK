{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd5e7406",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation\n",
    "\n",
    "**Project:** Global Electronics Retailer Dataset Analysis  \n",
    "**Author:** Ammar Siregar  \n",
    "**Purpose:** Clean and prepare data for analysis  \n",
    "\n",
    "This notebook handles data cleaning, preprocessing, and preparation of the final analysis dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90057512",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eceff06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom cleaning functions\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from data_cleaning import *\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb47511",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c35817b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "==================================================\n",
      "âœ“ Loaded 15266 customer records\n",
      "âœ“ Loaded 2517 product records\n",
      "âœ“ Loaded 62884 sales records\n",
      "âœ“ Loaded 67 store records\n",
      "âœ“ Loaded 11215 exchange rate records\n",
      "Loaded 15266 customers\n",
      "Loaded 2517 products\n",
      "Loaded 62884 sales records\n",
      "Loaded 67 stores\n",
      "Loaded 11215 exchange rate records\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading raw data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load datasets\n",
    "customers = load_customers_data('../data/raw/Customers.csv')\n",
    "products = load_products_data('../data/raw/Products.csv')\n",
    "sales = load_sales_data('../data/raw/Sales.csv')\n",
    "stores = load_stores_data('../data/raw/Stores.csv')\n",
    "exchange_rates = load_exchange_rates_data('../data/raw/Exchange_Rates.csv')\n",
    "\n",
    "print(f\"Loaded {len(customers)} customers\")\n",
    "print(f\"Loaded {len(products)} products\")\n",
    "print(f\"Loaded {len(sales)} sales records\")\n",
    "print(f\"Loaded {len(stores)} stores\")\n",
    "print(f\"Loaded {len(exchange_rates)} exchange rate records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105f4c5",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps\n",
    "\n",
    "### 1. Clean Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968e8d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning date columns...\n",
      "==============================\n",
      "âœ“ Date columns cleaned\n",
      "Sales date range: 2016-01-01 00:00:00 to 2021-02-20 00:00:00\n",
      "âœ“ Date columns cleaned\n",
      "Sales date range: 2016-01-01 00:00:00 to 2021-02-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning date columns...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Clean dates\n",
    "sales = clean_date_columns(sales)\n",
    "customers = clean_customer_dates(customers)\n",
    "stores = clean_store_dates(stores)\n",
    "exchange_rates = clean_exchange_dates(exchange_rates)\n",
    "\n",
    "print(\"âœ“ Date columns cleaned\")\n",
    "print(f\"Sales date range: {sales['Order Date'].min()} to {sales['Order Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec2551",
   "metadata": {},
   "source": [
    "### 2. Clean Price Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67e82e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning price columns...\n",
      "==============================\n",
      "Before cleaning:\n",
      "  Unit Cost USD Unit Price USD\n",
      "0        $6.62         $12.99 \n",
      "1        $6.62         $12.99 \n",
      "2        $7.40         $14.52 \n",
      "\n",
      "After cleaning:\n",
      "   Unit Cost USD  Unit Price USD\n",
      "0           6.62           12.99\n",
      "1           6.62           12.99\n",
      "2           7.40           14.52\n",
      "\n",
      "âœ“ Price columns cleaned and converted to numeric\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning price columns...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "print(products[['Unit Cost USD', 'Unit Price USD']].head(3))\n",
    "\n",
    "# Clean prices\n",
    "products = clean_price_columns(products)\n",
    "\n",
    "# After cleaning\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(products[['Unit Cost USD', 'Unit Price USD']].head(3))\n",
    "print(f\"\\nâœ“ Price columns cleaned and converted to numeric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd26819",
   "metadata": {},
   "source": [
    "### 3. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cc33dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "==============================\n",
      "Missing values before handling:\n",
      "Sales: 49719 missing values\n",
      "Products: 0 missing values\n",
      "Customers: 10 missing values\n",
      "Stores: 1 missing values\n",
      "\n",
      "âœ“ Missing values handled\n"
     ]
    }
   ],
   "source": [
    "print(\"Handling missing values...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check missing values before\n",
    "print(\"Missing values before handling:\")\n",
    "for name, df in [('Sales', sales), ('Products', products), ('Customers', customers), ('Stores', stores)]:\n",
    "    missing = df.isnull().sum().sum()\n",
    "    print(f\"{name}: {missing} missing values\")\n",
    "\n",
    "# Handle missing values\n",
    "sales = handle_missing_values(sales)\n",
    "products = handle_missing_values(products)\n",
    "customers = handle_missing_values(customers)\n",
    "stores = handle_missing_values(stores)\n",
    "\n",
    "print(\"\\nâœ“ Missing values handled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4724ea",
   "metadata": {},
   "source": [
    "### 4. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2db1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating cleaned data...\n",
      "==============================\n",
      "âœ“ Sales has required columns\n",
      "âœ“ Products has required columns\n",
      "âœ“ Customers has required columns\n",
      "âœ“ Stores has required columns\n",
      "âœ“ No negative prices\n",
      "âœ“ Reasonable date range\n",
      "âœ“ No duplicate ProductKeys\n",
      "âœ“ No duplicate CustomerKeys\n",
      "âœ“ No duplicate StoreKeys\n",
      "âœ“ Sales has required columns\n",
      "âœ“ Products has required columns\n",
      "âœ“ Customers has required columns\n",
      "âœ“ Stores has required columns\n",
      "âœ“ No negative prices\n",
      "âœ“ Reasonable date range\n",
      "âœ“ No duplicate ProductKeys\n",
      "âœ“ No duplicate CustomerKeys\n",
      "âœ“ No duplicate StoreKeys\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating cleaned data...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Validate data\n",
    "validation_results = validate_cleaned_data(sales, products, customers, stores)\n",
    "\n",
    "for check, result in validation_results.items():\n",
    "    status = \"âœ“\" if result else \"âœ—\"\n",
    "    print(f\"{status} {check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c048bad",
   "metadata": {},
   "source": [
    "## Data Integration\n",
    "\n",
    "### Merge all datasets into a comprehensive analysis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7a2162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating integrated dataset...\n",
      "========================================\n",
      "Starting with sales data: (62884, 9)\n",
      "After merging products: (62884, 18)\n",
      "After merging customers: (62884, 27)After merging customers: (62884, 27)\n",
      "After merging stores: (62884, 31)\n",
      "\n",
      "âœ“ Integrated dataset created with 62884 rows and 31 columns\n",
      "\n",
      "After merging stores: (62884, 31)\n",
      "\n",
      "âœ“ Integrated dataset created with 62884 rows and 31 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating integrated dataset...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Start with sales as the base\n",
    "print(f\"Starting with sales data: {sales.shape}\")\n",
    "\n",
    "# Merge with products\n",
    "sales_analysis = sales.merge(products, on='ProductKey', how='left')\n",
    "print(f\"After merging products: {sales_analysis.shape}\")\n",
    "\n",
    "# Merge with customers\n",
    "sales_analysis = sales_analysis.merge(customers, on='CustomerKey', how='left')\n",
    "print(f\"After merging customers: {sales_analysis.shape}\")\n",
    "\n",
    "# Merge with stores\n",
    "sales_analysis = sales_analysis.merge(stores, on='StoreKey', how='left')\n",
    "print(f\"After merging stores: {sales_analysis.shape}\")\n",
    "\n",
    "print(f\"\\nâœ“ Integrated dataset created with {sales_analysis.shape[0]} rows and {sales_analysis.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f332202",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Create calculated fields for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f99bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating calculated fields...\n",
      "===================================\n",
      "âœ“ Revenue, Cost, Profit, and Profit Margin calculated\n",
      "âœ“ Date features extracted\n",
      "âœ“ Customer age and age groups calculated\n",
      "âœ“ Delivery time features calculated\n",
      "\n",
      "Total features in final dataset: 44\n",
      "âœ“ Date features extracted\n",
      "âœ“ Customer age and age groups calculated\n",
      "âœ“ Delivery time features calculated\n",
      "\n",
      "Total features in final dataset: 44\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating calculated fields...\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Calculate revenue, cost, and profit\n",
    "sales_analysis['Revenue'] = sales_analysis['Quantity'] * sales_analysis['Unit Price USD']\n",
    "sales_analysis['Cost'] = sales_analysis['Quantity'] * sales_analysis['Unit Cost USD']\n",
    "sales_analysis['Profit'] = sales_analysis['Revenue'] - sales_analysis['Cost']\n",
    "sales_analysis['Profit Margin'] = (sales_analysis['Profit'] / sales_analysis['Revenue']) * 100\n",
    "\n",
    "print(\"âœ“ Revenue, Cost, Profit, and Profit Margin calculated\")\n",
    "\n",
    "# Extract date features\n",
    "sales_analysis['Year'] = sales_analysis['Order Date'].dt.year\n",
    "sales_analysis['Month'] = sales_analysis['Order Date'].dt.month\n",
    "sales_analysis['Quarter'] = sales_analysis['Order Date'].dt.quarter\n",
    "sales_analysis['Day of Week'] = sales_analysis['Order Date'].dt.day_name()\n",
    "sales_analysis['Month Name'] = sales_analysis['Order Date'].dt.month_name()\n",
    "sales_analysis['Week of Year'] = sales_analysis['Order Date'].dt.isocalendar().week\n",
    "\n",
    "print(\"âœ“ Date features extracted\")\n",
    "\n",
    "# Customer age calculation\n",
    "sales_analysis['Customer Age'] = (sales_analysis['Order Date'] - sales_analysis['Birthday']).dt.days / 365.25\n",
    "sales_analysis['Age Group'] = pd.cut(sales_analysis['Customer Age'], \n",
    "                                   bins=[0, 25, 35, 45, 55, 65, 100], \n",
    "                                   labels=['18-25', '26-35', '36-45', '46-55', '56-65', '65+'])\n",
    "\n",
    "print(\"âœ“ Customer age and age groups calculated\")\n",
    "\n",
    "# Delivery time analysis\n",
    "sales_analysis['Delivery Days'] = (sales_analysis['Delivery Date'] - sales_analysis['Order Date']).dt.days\n",
    "\n",
    "print(\"âœ“ Delivery time features calculated\")\n",
    "\n",
    "print(f\"\\nTotal features in final dataset: {sales_analysis.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56fa6d",
   "metadata": {},
   "source": [
    "## Data Quality Check on Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ecf5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data quality check...\n",
      "===================================\n",
      "Dataset shape: (62884, 44)\n",
      "Missing values: 99468\n",
      "Missing values: 99468\n",
      "Duplicate rows: 0\n",
      "\n",
      "Calculated field statistics:\n",
      "Revenue range: $0.95 to $31,999.90\n",
      "Profit range: $0.47 to $21,397.70\n",
      "Profit margin range: 48.9% to 66.9%\n",
      "\n",
      "Data validation:\n",
      "Negative revenue records: 0\n",
      "Negative quantity records: 0\n",
      "âœ“ Data validation passed\n",
      "Duplicate rows: 0\n",
      "\n",
      "Calculated field statistics:\n",
      "Revenue range: $0.95 to $31,999.90\n",
      "Profit range: $0.47 to $21,397.70\n",
      "Profit margin range: 48.9% to 66.9%\n",
      "\n",
      "Data validation:\n",
      "Negative revenue records: 0\n",
      "Negative quantity records: 0\n",
      "âœ“ Data validation passed\n"
     ]
    }
   ],
   "source": [
    "print(\"Final data quality check...\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"Dataset shape: {sales_analysis.shape}\")\n",
    "print(f\"Missing values: {sales_analysis.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {sales_analysis.duplicated().sum()}\")\n",
    "\n",
    "# Check calculated fields\n",
    "print(f\"\\nCalculated field statistics:\")\n",
    "print(f\"Revenue range: ${sales_analysis['Revenue'].min():.2f} to ${sales_analysis['Revenue'].max():,.2f}\")\n",
    "print(f\"Profit range: ${sales_analysis['Profit'].min():.2f} to ${sales_analysis['Profit'].max():,.2f}\")\n",
    "print(f\"Profit margin range: {sales_analysis['Profit Margin'].min():.1f}% to {sales_analysis['Profit Margin'].max():.1f}%\")\n",
    "\n",
    "# Check for negative values that might indicate issues\n",
    "negative_revenue = (sales_analysis['Revenue'] < 0).sum()\n",
    "negative_quantity = (sales_analysis['Quantity'] < 0).sum()\n",
    "\n",
    "print(f\"\\nData validation:\")\n",
    "print(f\"Negative revenue records: {negative_revenue}\")\n",
    "print(f\"Negative quantity records: {negative_quantity}\")\n",
    "\n",
    "if negative_revenue == 0 and negative_quantity == 0:\n",
    "    print(\"âœ“ Data validation passed\")\n",
    "else:\n",
    "    print(\"âš  Data validation issues found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ca7ec",
   "metadata": {},
   "source": [
    "## Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac5b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cleaned data...\n",
      "=========================\n",
      "âœ“ Individual cleaned datasets saved\n",
      "âœ“ Individual cleaned datasets saved\n",
      "âœ“ Complete analysis dataset saved\n",
      "âœ“ Data cleaning summary saved\n",
      "\n",
      "Data cleaning complete! Files saved to data/processed/\n",
      "âœ“ Complete analysis dataset saved\n",
      "âœ“ Data cleaning summary saved\n",
      "\n",
      "Data cleaning complete! Files saved to data/processed/\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving cleaned data...\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Save individual cleaned datasets\n",
    "customers.to_csv('../data/processed/customers_cleaned.csv', index=False)\n",
    "products.to_csv('../data/processed/products_cleaned.csv', index=False)\n",
    "sales.to_csv('../data/processed/sales_cleaned.csv', index=False)\n",
    "stores.to_csv('../data/processed/stores_cleaned.csv', index=False)\n",
    "exchange_rates.to_csv('../data/processed/exchange_rates_cleaned.csv', index=False)\n",
    "\n",
    "print(\"âœ“ Individual cleaned datasets saved\")\n",
    "\n",
    "# Save the integrated analysis dataset\n",
    "sales_analysis.to_csv('../data/processed/sales_analysis_complete.csv', index=False)\n",
    "print(\"âœ“ Complete analysis dataset saved\")\n",
    "\n",
    "# Create and save data summary\n",
    "data_summary = {\n",
    "    'Dataset': ['Customers', 'Products', 'Sales', 'Stores', 'Exchange Rates', 'Sales Analysis'],\n",
    "    'Records': [len(customers), len(products), len(sales), len(stores), len(exchange_rates), len(sales_analysis)],\n",
    "    'Columns': [customers.shape[1], products.shape[1], sales.shape[1], stores.shape[1], exchange_rates.shape[1], sales_analysis.shape[1]],\n",
    "    'Missing Values': [customers.isnull().sum().sum(), products.isnull().sum().sum(), \n",
    "                      sales.isnull().sum().sum(), stores.isnull().sum().sum(), \n",
    "                      exchange_rates.isnull().sum().sum(), sales_analysis.isnull().sum().sum()]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(data_summary)\n",
    "summary_df.to_csv('../data/processed/data_cleaning_summary.csv', index=False)\n",
    "print(\"âœ“ Data cleaning summary saved\")\n",
    "\n",
    "print(\"\\nData cleaning complete! Files saved to data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c66188",
   "metadata": {},
   "source": [
    "## Cleaning Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3aaaac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA CLEANING SUMMARY\n",
      "==================================================\n",
      "\n",
      "ðŸ§¹ CLEANING OPERATIONS COMPLETED:\n",
      "   âœ“ Date columns converted to datetime format\n",
      "   âœ“ Price columns cleaned and converted to numeric\n",
      "   âœ“ Missing values handled appropriately\n",
      "   âœ“ Data validation checks passed\n",
      "   âœ“ Datasets integrated successfully\n",
      "\n",
      "ðŸ“Š FINAL DATASET STATISTICS:\n",
      "   â€¢ Total records: 62,884\n",
      "   â€¢ Total features: 44\n",
      "   â€¢ Date range: 2016-01-01 to 2021-02-20\n",
      "   â€¢ Total revenue: $55,755,479.59\n",
      "   â€¢ Total profit: $32,662,688.38\n",
      "\n",
      "ðŸ’¾ FILES CREATED:\n",
      "   â€¢ Individual cleaned datasets in data/processed/\n",
      "   â€¢ Complete analysis dataset: sales_analysis_complete.csv\n",
      "   â€¢ Data cleaning summary: data_cleaning_summary.csv\n",
      "\n",
      "âœ… Data is now ready for analysis and visualization!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\"\"\n",
    "ðŸ§¹ CLEANING OPERATIONS COMPLETED:\n",
    "   âœ“ Date columns converted to datetime format\n",
    "   âœ“ Price columns cleaned and converted to numeric\n",
    "   âœ“ Missing values handled appropriately\n",
    "   âœ“ Data validation checks passed\n",
    "   âœ“ Datasets integrated successfully\n",
    "\n",
    "ðŸ“Š FINAL DATASET STATISTICS:\n",
    "   â€¢ Total records: {len(sales_analysis):,}\n",
    "   â€¢ Total features: {sales_analysis.shape[1]}\n",
    "   â€¢ Date range: {sales_analysis['Order Date'].min().strftime('%Y-%m-%d')} to {sales_analysis['Order Date'].max().strftime('%Y-%m-%d')}\n",
    "   â€¢ Total revenue: ${sales_analysis['Revenue'].sum():,.2f}\n",
    "   â€¢ Total profit: ${sales_analysis['Profit'].sum():,.2f}\n",
    "\n",
    "ðŸ’¾ FILES CREATED:\n",
    "   â€¢ Individual cleaned datasets in data/processed/\n",
    "   â€¢ Complete analysis dataset: sales_analysis_complete.csv\n",
    "   â€¢ Data cleaning summary: data_cleaning_summary.csv\n",
    "\n",
    "âœ… Data is now ready for analysis and visualization!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
