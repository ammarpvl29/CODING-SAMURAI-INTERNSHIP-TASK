{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd5e7406",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation\n",
    "\n",
    "**Project:** Global Electronics Retailer Dataset Analysis  \n",
    "**Author:** Ammar Siregar  \n",
    "**Purpose:** Clean and prepare data for analysis  \n",
    "\n",
    "This notebook handles data cleaning, preprocessing, and preparation of the final analysis dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90057512",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eceff06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom cleaning functions\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from data_cleaning import *\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb47511",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c35817b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "==================================================\n",
      "✓ Loaded 15266 customer records\n",
      "✓ Loaded 2517 product records\n",
      "✓ Loaded 62884 sales records\n",
      "✓ Loaded 67 store records\n",
      "✓ Loaded 11215 exchange rate records\n",
      "Loaded 15266 customers\n",
      "Loaded 2517 products\n",
      "Loaded 62884 sales records\n",
      "Loaded 67 stores\n",
      "Loaded 11215 exchange rate records\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading raw data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load datasets\n",
    "customers = load_customers_data('../data/raw/Customers.csv')\n",
    "products = load_products_data('../data/raw/Products.csv')\n",
    "sales = load_sales_data('../data/raw/Sales.csv')\n",
    "stores = load_stores_data('../data/raw/Stores.csv')\n",
    "exchange_rates = load_exchange_rates_data('../data/raw/Exchange_Rates.csv')\n",
    "\n",
    "print(f\"Loaded {len(customers)} customers\")\n",
    "print(f\"Loaded {len(products)} products\")\n",
    "print(f\"Loaded {len(sales)} sales records\")\n",
    "print(f\"Loaded {len(stores)} stores\")\n",
    "print(f\"Loaded {len(exchange_rates)} exchange rate records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105f4c5",
   "metadata": {},
   "source": [
    "## Data Cleaning Steps\n",
    "\n",
    "### 1. Clean Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968e8d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning date columns...\n",
      "==============================\n",
      "✓ Date columns cleaned\n",
      "Sales date range: 2016-01-01 00:00:00 to 2021-02-20 00:00:00\n",
      "✓ Date columns cleaned\n",
      "Sales date range: 2016-01-01 00:00:00 to 2021-02-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning date columns...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Clean dates\n",
    "sales = clean_date_columns(sales)\n",
    "customers = clean_customer_dates(customers)\n",
    "stores = clean_store_dates(stores)\n",
    "exchange_rates = clean_exchange_dates(exchange_rates)\n",
    "\n",
    "print(\"✓ Date columns cleaned\")\n",
    "print(f\"Sales date range: {sales['Order Date'].min()} to {sales['Order Date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec2551",
   "metadata": {},
   "source": [
    "### 2. Clean Price Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67e82e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning price columns...\n",
      "==============================\n",
      "Before cleaning:\n",
      "  Unit Cost USD Unit Price USD\n",
      "0        $6.62         $12.99 \n",
      "1        $6.62         $12.99 \n",
      "2        $7.40         $14.52 \n",
      "\n",
      "After cleaning:\n",
      "   Unit Cost USD  Unit Price USD\n",
      "0           6.62           12.99\n",
      "1           6.62           12.99\n",
      "2           7.40           14.52\n",
      "\n",
      "✓ Price columns cleaned and converted to numeric\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning price columns...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "print(products[['Unit Cost USD', 'Unit Price USD']].head(3))\n",
    "\n",
    "# Clean prices\n",
    "products = clean_price_columns(products)\n",
    "\n",
    "# After cleaning\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(products[['Unit Cost USD', 'Unit Price USD']].head(3))\n",
    "print(f\"\\n✓ Price columns cleaned and converted to numeric\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd26819",
   "metadata": {},
   "source": [
    "### 3. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cc33dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "==============================\n",
      "Missing values before handling:\n",
      "Sales: 49719 missing values\n",
      "Products: 0 missing values\n",
      "Customers: 10 missing values\n",
      "Stores: 1 missing values\n",
      "\n",
      "✓ Missing values handled\n"
     ]
    }
   ],
   "source": [
    "print(\"Handling missing values...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Check missing values before\n",
    "print(\"Missing values before handling:\")\n",
    "for name, df in [('Sales', sales), ('Products', products), ('Customers', customers), ('Stores', stores)]:\n",
    "    missing = df.isnull().sum().sum()\n",
    "    print(f\"{name}: {missing} missing values\")\n",
    "\n",
    "# Handle missing values\n",
    "sales = handle_missing_values(sales)\n",
    "products = handle_missing_values(products)\n",
    "customers = handle_missing_values(customers)\n",
    "stores = handle_missing_values(stores)\n",
    "\n",
    "print(\"\\n✓ Missing values handled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4724ea",
   "metadata": {},
   "source": [
    "### 4. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2db1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating cleaned data...\n",
      "==============================\n",
      "✓ Sales has required columns\n",
      "✓ Products has required columns\n",
      "✓ Customers has required columns\n",
      "✓ Stores has required columns\n",
      "✓ No negative prices\n",
      "✓ Reasonable date range\n",
      "✓ No duplicate ProductKeys\n",
      "✓ No duplicate CustomerKeys\n",
      "✓ No duplicate StoreKeys\n",
      "✓ Sales has required columns\n",
      "✓ Products has required columns\n",
      "✓ Customers has required columns\n",
      "✓ Stores has required columns\n",
      "✓ No negative prices\n",
      "✓ Reasonable date range\n",
      "✓ No duplicate ProductKeys\n",
      "✓ No duplicate CustomerKeys\n",
      "✓ No duplicate StoreKeys\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating cleaned data...\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Validate data\n",
    "validation_results = validate_cleaned_data(sales, products, customers, stores)\n",
    "\n",
    "for check, result in validation_results.items():\n",
    "    status = \"✓\" if result else \"✗\"\n",
    "    print(f\"{status} {check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c048bad",
   "metadata": {},
   "source": [
    "## Data Integration\n",
    "\n",
    "### Merge all datasets into a comprehensive analysis dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7a2162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating integrated dataset...\n",
      "========================================\n",
      "Starting with sales data: (62884, 9)\n",
      "After merging products: (62884, 18)\n",
      "After merging customers: (62884, 27)After merging customers: (62884, 27)\n",
      "After merging stores: (62884, 31)\n",
      "\n",
      "✓ Integrated dataset created with 62884 rows and 31 columns\n",
      "\n",
      "After merging stores: (62884, 31)\n",
      "\n",
      "✓ Integrated dataset created with 62884 rows and 31 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating integrated dataset...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Start with sales as the base\n",
    "print(f\"Starting with sales data: {sales.shape}\")\n",
    "\n",
    "# Merge with products\n",
    "sales_analysis = sales.merge(products, on='ProductKey', how='left')\n",
    "print(f\"After merging products: {sales_analysis.shape}\")\n",
    "\n",
    "# Merge with customers\n",
    "sales_analysis = sales_analysis.merge(customers, on='CustomerKey', how='left')\n",
    "print(f\"After merging customers: {sales_analysis.shape}\")\n",
    "\n",
    "# Merge with stores\n",
    "sales_analysis = sales_analysis.merge(stores, on='StoreKey', how='left')\n",
    "print(f\"After merging stores: {sales_analysis.shape}\")\n",
    "\n",
    "print(f\"\\n✓ Integrated dataset created with {sales_analysis.shape[0]} rows and {sales_analysis.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f332202",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Create calculated fields for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f99bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating calculated fields...\n",
      "===================================\n",
      "✓ Revenue, Cost, Profit, and Profit Margin calculated\n",
      "✓ Date features extracted\n",
      "✓ Customer age and age groups calculated\n",
      "✓ Delivery time features calculated\n",
      "\n",
      "Total features in final dataset: 44\n",
      "✓ Date features extracted\n",
      "✓ Customer age and age groups calculated\n",
      "✓ Delivery time features calculated\n",
      "\n",
      "Total features in final dataset: 44\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating calculated fields...\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Calculate revenue, cost, and profit\n",
    "sales_analysis['Revenue'] = sales_analysis['Quantity'] * sales_analysis['Unit Price USD']\n",
    "sales_analysis['Cost'] = sales_analysis['Quantity'] * sales_analysis['Unit Cost USD']\n",
    "sales_analysis['Profit'] = sales_analysis['Revenue'] - sales_analysis['Cost']\n",
    "sales_analysis['Profit Margin'] = (sales_analysis['Profit'] / sales_analysis['Revenue']) * 100\n",
    "\n",
    "print(\"✓ Revenue, Cost, Profit, and Profit Margin calculated\")\n",
    "\n",
    "# Extract date features\n",
    "sales_analysis['Year'] = sales_analysis['Order Date'].dt.year\n",
    "sales_analysis['Month'] = sales_analysis['Order Date'].dt.month\n",
    "sales_analysis['Quarter'] = sales_analysis['Order Date'].dt.quarter\n",
    "sales_analysis['Day of Week'] = sales_analysis['Order Date'].dt.day_name()\n",
    "sales_analysis['Month Name'] = sales_analysis['Order Date'].dt.month_name()\n",
    "sales_analysis['Week of Year'] = sales_analysis['Order Date'].dt.isocalendar().week\n",
    "\n",
    "print(\"✓ Date features extracted\")\n",
    "\n",
    "# Customer age calculation\n",
    "sales_analysis['Customer Age'] = (sales_analysis['Order Date'] - sales_analysis['Birthday']).dt.days / 365.25\n",
    "sales_analysis['Age Group'] = pd.cut(sales_analysis['Customer Age'], \n",
    "                                   bins=[0, 25, 35, 45, 55, 65, 100], \n",
    "                                   labels=['18-25', '26-35', '36-45', '46-55', '56-65', '65+'])\n",
    "\n",
    "print(\"✓ Customer age and age groups calculated\")\n",
    "\n",
    "# Delivery time analysis\n",
    "sales_analysis['Delivery Days'] = (sales_analysis['Delivery Date'] - sales_analysis['Order Date']).dt.days\n",
    "\n",
    "print(\"✓ Delivery time features calculated\")\n",
    "\n",
    "print(f\"\\nTotal features in final dataset: {sales_analysis.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56fa6d",
   "metadata": {},
   "source": [
    "## Data Quality Check on Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ecf5412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data quality check...\n",
      "===================================\n",
      "Dataset shape: (62884, 44)\n",
      "Missing values: 99468\n",
      "Missing values: 99468\n",
      "Duplicate rows: 0\n",
      "\n",
      "Calculated field statistics:\n",
      "Revenue range: $0.95 to $31,999.90\n",
      "Profit range: $0.47 to $21,397.70\n",
      "Profit margin range: 48.9% to 66.9%\n",
      "\n",
      "Data validation:\n",
      "Negative revenue records: 0\n",
      "Negative quantity records: 0\n",
      "✓ Data validation passed\n",
      "Duplicate rows: 0\n",
      "\n",
      "Calculated field statistics:\n",
      "Revenue range: $0.95 to $31,999.90\n",
      "Profit range: $0.47 to $21,397.70\n",
      "Profit margin range: 48.9% to 66.9%\n",
      "\n",
      "Data validation:\n",
      "Negative revenue records: 0\n",
      "Negative quantity records: 0\n",
      "✓ Data validation passed\n"
     ]
    }
   ],
   "source": [
    "print(\"Final data quality check...\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"Dataset shape: {sales_analysis.shape}\")\n",
    "print(f\"Missing values: {sales_analysis.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {sales_analysis.duplicated().sum()}\")\n",
    "\n",
    "# Check calculated fields\n",
    "print(f\"\\nCalculated field statistics:\")\n",
    "print(f\"Revenue range: ${sales_analysis['Revenue'].min():.2f} to ${sales_analysis['Revenue'].max():,.2f}\")\n",
    "print(f\"Profit range: ${sales_analysis['Profit'].min():.2f} to ${sales_analysis['Profit'].max():,.2f}\")\n",
    "print(f\"Profit margin range: {sales_analysis['Profit Margin'].min():.1f}% to {sales_analysis['Profit Margin'].max():.1f}%\")\n",
    "\n",
    "# Check for negative values that might indicate issues\n",
    "negative_revenue = (sales_analysis['Revenue'] < 0).sum()\n",
    "negative_quantity = (sales_analysis['Quantity'] < 0).sum()\n",
    "\n",
    "print(f\"\\nData validation:\")\n",
    "print(f\"Negative revenue records: {negative_revenue}\")\n",
    "print(f\"Negative quantity records: {negative_quantity}\")\n",
    "\n",
    "if negative_revenue == 0 and negative_quantity == 0:\n",
    "    print(\"✓ Data validation passed\")\n",
    "else:\n",
    "    print(\"⚠ Data validation issues found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ca7ec",
   "metadata": {},
   "source": [
    "## Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac5b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cleaned data...\n",
      "=========================\n",
      "✓ Individual cleaned datasets saved\n",
      "✓ Individual cleaned datasets saved\n",
      "✓ Complete analysis dataset saved\n",
      "✓ Data cleaning summary saved\n",
      "\n",
      "Data cleaning complete! Files saved to data/processed/\n",
      "✓ Complete analysis dataset saved\n",
      "✓ Data cleaning summary saved\n",
      "\n",
      "Data cleaning complete! Files saved to data/processed/\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving cleaned data...\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Save individual cleaned datasets\n",
    "customers.to_csv('../data/processed/customers_cleaned.csv', index=False)\n",
    "products.to_csv('../data/processed/products_cleaned.csv', index=False)\n",
    "sales.to_csv('../data/processed/sales_cleaned.csv', index=False)\n",
    "stores.to_csv('../data/processed/stores_cleaned.csv', index=False)\n",
    "exchange_rates.to_csv('../data/processed/exchange_rates_cleaned.csv', index=False)\n",
    "\n",
    "print(\"✓ Individual cleaned datasets saved\")\n",
    "\n",
    "# Save the integrated analysis dataset\n",
    "sales_analysis.to_csv('../data/processed/sales_analysis_complete.csv', index=False)\n",
    "print(\"✓ Complete analysis dataset saved\")\n",
    "\n",
    "# Create and save data summary\n",
    "data_summary = {\n",
    "    'Dataset': ['Customers', 'Products', 'Sales', 'Stores', 'Exchange Rates', 'Sales Analysis'],\n",
    "    'Records': [len(customers), len(products), len(sales), len(stores), len(exchange_rates), len(sales_analysis)],\n",
    "    'Columns': [customers.shape[1], products.shape[1], sales.shape[1], stores.shape[1], exchange_rates.shape[1], sales_analysis.shape[1]],\n",
    "    'Missing Values': [customers.isnull().sum().sum(), products.isnull().sum().sum(), \n",
    "                      sales.isnull().sum().sum(), stores.isnull().sum().sum(), \n",
    "                      exchange_rates.isnull().sum().sum(), sales_analysis.isnull().sum().sum()]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(data_summary)\n",
    "summary_df.to_csv('../data/processed/data_cleaning_summary.csv', index=False)\n",
    "print(\"✓ Data cleaning summary saved\")\n",
    "\n",
    "print(\"\\nData cleaning complete! Files saved to data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c66188",
   "metadata": {},
   "source": [
    "## Cleaning Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3aaaac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA CLEANING SUMMARY\n",
      "==================================================\n",
      "\n",
      "🧹 CLEANING OPERATIONS COMPLETED:\n",
      "   ✓ Date columns converted to datetime format\n",
      "   ✓ Price columns cleaned and converted to numeric\n",
      "   ✓ Missing values handled appropriately\n",
      "   ✓ Data validation checks passed\n",
      "   ✓ Datasets integrated successfully\n",
      "\n",
      "📊 FINAL DATASET STATISTICS:\n",
      "   • Total records: 62,884\n",
      "   • Total features: 44\n",
      "   • Date range: 2016-01-01 to 2021-02-20\n",
      "   • Total revenue: $55,755,479.59\n",
      "   • Total profit: $32,662,688.38\n",
      "\n",
      "💾 FILES CREATED:\n",
      "   • Individual cleaned datasets in data/processed/\n",
      "   • Complete analysis dataset: sales_analysis_complete.csv\n",
      "   • Data cleaning summary: data_cleaning_summary.csv\n",
      "\n",
      "✅ Data is now ready for analysis and visualization!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA CLEANING SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\"\"\n",
    "🧹 CLEANING OPERATIONS COMPLETED:\n",
    "   ✓ Date columns converted to datetime format\n",
    "   ✓ Price columns cleaned and converted to numeric\n",
    "   ✓ Missing values handled appropriately\n",
    "   ✓ Data validation checks passed\n",
    "   ✓ Datasets integrated successfully\n",
    "\n",
    "📊 FINAL DATASET STATISTICS:\n",
    "   • Total records: {len(sales_analysis):,}\n",
    "   • Total features: {sales_analysis.shape[1]}\n",
    "   • Date range: {sales_analysis['Order Date'].min().strftime('%Y-%m-%d')} to {sales_analysis['Order Date'].max().strftime('%Y-%m-%d')}\n",
    "   • Total revenue: ${sales_analysis['Revenue'].sum():,.2f}\n",
    "   • Total profit: ${sales_analysis['Profit'].sum():,.2f}\n",
    "\n",
    "💾 FILES CREATED:\n",
    "   • Individual cleaned datasets in data/processed/\n",
    "   • Complete analysis dataset: sales_analysis_complete.csv\n",
    "   • Data cleaning summary: data_cleaning_summary.csv\n",
    "\n",
    "✅ Data is now ready for analysis and visualization!\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
